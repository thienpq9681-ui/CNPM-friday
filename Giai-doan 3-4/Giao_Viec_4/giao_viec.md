# ğŸ¯ GIAO_VIEC_4 - Phase 4 (AI Features, Evaluation & Advanced)

**NgÃ y báº¯t Ä‘áº§u:** Feb 15, 2026  
**Deadline:** Feb 21, 2026  
**Má»¥c tiÃªu:** AI Mentoring, Advanced Evaluation, Peer Reviews, Reports

---

## ï¿½ TIáº¾N Äá»˜ PHASE 4

| ThÃ nh viÃªn | Task | Status |
|------------|------|--------|
| **BE1** | AI Mentoring Integration | âœ… **HOÃ€N THÃ€NH** |
| BE2 | Peer Reviews Module | ğŸ”„ ChÆ°a báº¯t Ä‘áº§u |
| BE3 | Milestones & Submissions | ğŸ”„ ChÆ°a báº¯t Ä‘áº§u |
| BE4 | Evaluation Details & Resources | ğŸ”„ ChÆ°a báº¯t Ä‘áº§u |
| FE1 | AI Mentoring UI | ğŸ”„ ChÆ°a báº¯t Ä‘áº§u |
| FE2 | Peer Review UI | ğŸ”„ ChÆ°a báº¯t Ä‘áº§u |
| FE3 | Milestones & Reports UI | ğŸ”„ ChÆ°a báº¯t Ä‘áº§u |

### âœ… BE1 ÄÃ£ hoÃ n thÃ nh (cÃ¡c thÃ nh viÃªn khÃ¡c cÃ³ thá»ƒ sá»­ dá»¥ng):

**Files Ä‘Ã£ táº¡o:**
- `backend/app/services/ai_service.py` - AIService vá»›i Google Gemini integration
- `backend/app/api/v1/mentoring.py` - All CRUD + AI suggestion endpoints

**API Endpoints cÃ³ sáºµn:**
| Endpoint | Method | MÃ´ táº£ |
|----------|--------|-------|
| `/api/v1/mentoring/logs` | POST | Táº¡o mentoring log |
| `/api/v1/mentoring/logs` | GET | Danh sÃ¡ch logs (query: team_id) |
| `/api/v1/mentoring/logs/{id}` | GET | Chi tiáº¿t log |
| `/api/v1/mentoring/logs/{id}` | PUT | Cáº­p nháº­t log |
| `/api/v1/mentoring/logs/{id}` | DELETE | XÃ³a log |
| `/api/v1/mentoring/suggestions` | POST | Láº¥y AI suggestions |
| `/api/v1/mentoring/team-progress/{id}` | GET | Team progress analytics |
| `/api/v1/mentoring/analyze-reviews/{id}` | POST | AI analyze peer reviews |

**CÃ¡ch sá»­ dá»¥ng AIService cho BE2, BE3, BE4:**
```python
from app.services.ai_service import AIService

ai = AIService()

# Generate mentoring suggestions
suggestions = await ai.generate_mentoring_suggestions(team_data, reviews, tasks)

# Analyze peer reviews
analysis = await ai.analyze_peer_reviews(reviews)

# Generate task breakdown
breakdown = await ai.generate_task_breakdown(task_description)
```

**LÆ°u Ã½:**
- Náº¿u khÃ´ng cÃ³ `GOOGLE_GEMINI_API_KEY` trong .env, AI sáº½ tráº£ vá» mock response
- Rate limiting: 1 second minimum giá»¯a cÃ¡c API calls

---

## ï¿½ğŸ“Š TÃ¬nh tráº¡ng API sau Phase 3

### âœ… ÄÃ£ hoÃ n thÃ nh (Phase 1-3):
| Module | Endpoints | Status |
|--------|-----------|--------|
| Core (Auth, Users, Profile) | 5 | âœ… |
| Topics & Evaluations | 7 | âœ… |
| Teams | 7 | âœ… |
| Tasks & Sprints | 10 | âœ… |
| Projects | 4 | âœ… |
| Academic (Classes, Subjects, etc.) | 22 | âœ… |
| Notifications | 6 | âœ… |
| Channels | 4 | âœ… (Phase 3) |
| Messages | 5 | âœ… (Phase 3) |
| Meetings | 6 | âœ… (Phase 3) |
| Semesters (complete) | 5 | âœ… (Phase 3) |

**Tá»•ng: ~80 endpoints**

### ğŸ”´ Cáº§n lÃ m Phase 4:
| Module | Endpoints cáº§n | Priority |
|--------|--------------|----------|
| AI Mentoring | 4 | HIGH |
| Peer Reviews | 5 | HIGH |
| Milestones & Checkpoints | 6 | MEDIUM |
| Submissions | 5 | MEDIUM |
| Evaluation Details | 4 | MEDIUM |
| Resources | 4 | LOW |
| Reports/Analytics | 3 | LOW |

**Target Phase 4:** ~110 endpoints total

---

## ğŸ‘¥ PhÃ¢n cÃ´ng Phase 4

### ğŸ”´ BE1 (AI Mentoring Integration) âœ… HOÃ€N THÃ€NH
**Má»¥c tiÃªu:** Integrate Google Gemini API for mentoring suggestions

**CÃ´ng viá»‡c:**
- [x] Configure Gemini API in `app/core/config.py`
- [x] Create `app/services/ai_service.py` (enhance existing)
- [x] Create `app/schemas/mentoring.py` (trong mentoring.py endpoint)
- [x] Create `app/api/v1/mentoring.py`
- [x] Implement endpoints:
  - `POST /api/v1/mentoring/logs` (create mentoring log)
  - `GET /api/v1/mentoring/logs?team_id={id}` (list logs)
  - `GET /api/v1/mentoring/logs/{id}` (log details)
  - `PUT /api/v1/mentoring/logs/{id}` (update log)
  - `DELETE /api/v1/mentoring/logs/{id}` (delete log)
  - `POST /api/v1/mentoring/suggestions` (get AI suggestions)
  - `GET /api/v1/mentoring/team-progress/{team_id}` (get team analytics)
  - `POST /api/v1/mentoring/analyze-reviews/{team_id}` (AI analyze peer reviews)
- [x] Implement AI suggestion generation:
  - Analyze team progress (sprint velocity, task completion)
  - Analyze peer reviews (sentiment, issues)
  - Generate actionable recommendations
- [x] Add rate limiting for Gemini API
- [x] Test AI responses for quality

**Success criteria:**
- âœ… AI generates relevant mentoring suggestions
- âœ… Rate limiting prevents API abuse (1 second minimum interval)
- âœ… Suggestions are stored in mentoring logs
- âœ… Response time < 5 seconds

**Files Ä‘Ã£ táº¡o:**
```
backend/app/
â”œâ”€â”€ services/ai_service.py        # âœ… Google Gemini integration (~350 lines)
â”œâ”€â”€ api/v1/mentoring.py           # âœ… All CRUD + AI endpoints (~520 lines)
â””â”€â”€ core/config.py                # âœ… GOOGLE_GEMINI_API_KEY added
```

**Ghi chÃº BE1 (HoÃ n thÃ nh ngÃ y: Feb 2026):**
- Sá»­ dá»¥ng `google-generativeai==0.8.0` vá»›i model `gemini-1.5-flash`
- Mock fallback khi khÃ´ng cÃ³ API key (development mode)
- AIService class vá»›i lazy initialization cá»§a Gemini client
- Rate limiting: 1 second minimum giá»¯a cÃ¡c request
- Vietnamese language prompts vÃ  responses
- MentoringLog model Ä‘Ã£ cáº­p nháº­t vá»›i cÃ¡c fields: mentor_id, session_notes, discussion_points, feedback
- Endpoints Ä‘Ã£ Ä‘Äƒng kÃ½ trong api.py router

**Endpoints Testing Status:**
| Endpoint | Status |
|----------|--------|
| POST /api/v1/mentoring/logs | âœ… Tested |
| GET /api/v1/mentoring/logs | âœ… Tested |
| POST /api/v1/mentoring/suggestions | âœ… Tested (mock response) |

**AI Prompt Template:**
```python
def generate_mentoring_prompt(team_data, reviews, tasks):
    return f"""
    You are an academic mentor for a project team.
    
    Team Progress:
    - Sprint completion rate: {team_data.sprint_velocity}%
    - Tasks completed: {team_data.tasks_done}/{team_data.tasks_total}
    - Days until deadline: {team_data.days_remaining}
    
    Recent Peer Reviews (anonymized):
    {format_reviews(reviews)}
    
    Current Blockers:
    {format_blockers(tasks)}
    
    Provide 3-5 specific, actionable recommendations for:
    1. Improving team collaboration
    2. Addressing any skill gaps
    3. Meeting the project deadline
    
    Be constructive and supportive in tone.
    """
```

---

### ğŸŸ¡ BE2 (Peer Reviews Module)
**Má»¥c tiÃªu:** Implement anonymous peer review system

**CÃ´ng viá»‡c:**
- [ ] Create `app/schemas/peer_review.py`
- [ ] Create `app/api/v1/peer_reviews.py`
- [ ] Register routes in `api.py`
- [ ] Implement endpoints:
  - `POST /api/v1/peer-reviews` (submit review)
  - `GET /api/v1/peer-reviews?team_id={id}` (list reviews for team)
  - `GET /api/v1/peer-reviews/my-reviews` (reviews I've submitted)
  - `GET /api/v1/peer-reviews/about-me` (reviews about me)
  - `GET /api/v1/peer-reviews/{id}` (review details)
- [ ] Implement anonymization logic
- [ ] Add review period enforcement (only during sprints)
- [ ] Create aggregation for team analytics

**Success criteria:**
- Reviews are truly anonymous (reviewer not visible to reviewed)
- Can only review team members
- One review per team member per sprint
- Aggregated scores calculated correctly

**Schema:**
```python
class PeerReviewCreate(BaseModel):
    team_id: int
    reviewed_user_id: UUID
    sprint_id: int
    collaboration_score: int  # 1-5
    communication_score: int  # 1-5
    contribution_score: int  # 1-5
    comment: Optional[str] = None
    
    @validator('collaboration_score', 'communication_score', 'contribution_score')
    def validate_score(cls, v):
        if not 1 <= v <= 5:
            raise ValueError('Score must be between 1 and 5')
        return v

class PeerReviewResponse(BaseModel):
    id: int
    team_id: int
    # NO reviewer_id for anonymity!
    reviewed_user_id: UUID
    reviewed_user_name: str
    sprint_id: int
    collaboration_score: int
    communication_score: int
    contribution_score: int
    comment: Optional[str]
    created_at: datetime
```

---

### ğŸŸ  BE3 (Milestones & Submissions)
**Má»¥c tiÃªu:** Implement milestone tracking and submission system

**CÃ´ng viá»‡c:**
- [ ] Create `app/schemas/milestone.py`
- [ ] Create `app/schemas/submission.py`
- [ ] Create `app/api/v1/milestones.py`
- [ ] Create `app/api/v1/submissions.py`
- [ ] Implement endpoints:
  - **Milestones:**
    - `POST /api/v1/milestones` (create milestone)
    - `GET /api/v1/milestones?project_id={id}` (list)
    - `GET /api/v1/milestones/{id}` (details)
    - `PUT /api/v1/milestones/{id}` (update)
    - `DELETE /api/v1/milestones/{id}` (delete)
  - **Checkpoints:**
    - `POST /api/v1/milestones/{id}/checkpoints` (add checkpoint)
    - `GET /api/v1/milestones/{id}/checkpoints` (list checkpoints)
  - **Submissions:**
    - `POST /api/v1/submissions` (submit for checkpoint)
    - `GET /api/v1/submissions?checkpoint_id={id}` (list)
    - `GET /api/v1/submissions/{id}` (details)
    - `PUT /api/v1/submissions/{id}` (update - before deadline)
    - `PATCH /api/v1/submissions/{id}/grade` (lecturer grades)

**Success criteria:**
- Milestones have deadlines enforced
- Submissions blocked after deadline (unless lecturer allows late)
- Grading workflow works
- File upload support (if needed)

**Schema:**
```python
class MilestoneCreate(BaseModel):
    project_id: int
    name: str
    description: Optional[str]
    deadline: datetime
    weight: float = 1.0  # Weight in final grade

class CheckpointCreate(BaseModel):
    milestone_id: int
    description: str
    required: bool = True

class SubmissionCreate(BaseModel):
    checkpoint_id: int
    team_id: int
    content: str
    file_url: Optional[str]  # Link to uploaded file
```

---

### ğŸŸ  BE4 (Evaluation Details & Resources)
**Má»¥c tiÃªu:** Complete evaluation system and resource management

**CÃ´ng viá»‡c:**
- [ ] Enhance existing evaluation endpoints with details
- [ ] Create `app/schemas/resource.py`
- [ ] Create `app/api/v1/resources.py`
- [ ] Implement endpoints:
  - **Evaluation Details:**
    - `POST /api/v1/evaluations/{id}/details` (add criteria score)
    - `GET /api/v1/evaluations/{id}/details` (list all criteria scores)
    - `PUT /api/v1/evaluations/{id}/details/{criteria_id}` (update score)
    - `GET /api/v1/evaluations/{id}/summary` (aggregated scores)
  - **Resources:**
    - `POST /api/v1/resources` (share resource)
    - `GET /api/v1/resources?team_id={id}` (list team resources)
    - `GET /api/v1/resources/{id}` (resource details)
    - `DELETE /api/v1/resources/{id}` (remove resource)
- [ ] Add resource types (link, file, document)
- [ ] Add resource tagging for search

**Success criteria:**
- Evaluation details linked to criteria
- Final scores calculated from criteria weights
- Resources organized by team
- Search/filter by resource type

**Schema:**
```python
class EvaluationDetailCreate(BaseModel):
    evaluation_id: int
    criteria_id: int
    score: float
    comment: Optional[str]
    
    @validator('score')
    def validate_score(cls, v, values):
        # Score should not exceed max_score from criteria
        return v

class ResourceCreate(BaseModel):
    team_id: int
    title: str
    description: Optional[str]
    resource_type: str  # "link", "file", "document"
    url: str
    tags: List[str] = []
```

---

### ğŸŸ¢ FE1 (AI Mentoring + Evaluation UI)
**Má»¥c tiÃªu:** Build AI mentoring dashboard and evaluation interface

**CÃ´ng viá»‡c:**
- [ ] Create `frontend/src/services/mentoringService.js`
- [ ] Create `frontend/src/services/evaluationService.js`
- [ ] Create components:
  - [ ] `MentoringDashboard.jsx` (main page)
  - [ ] `MentoringLogList.jsx` (history)
  - [ ] `AIRecommendations.jsx` (AI suggestions display)
  - [ ] `RequestMentoringModal.jsx` (trigger AI analysis)
  - [ ] `EvaluationForm.jsx` (lecturer evaluates team)
  - [ ] `EvaluationCriteriaList.jsx` (criteria with scores)
  - [ ] `GradesSummary.jsx` (show final grades)
- [ ] Create page: `frontend/src/pages/MentoringPage.jsx`
- [ ] Create page: `frontend/src/pages/EvaluationPage.jsx`
- [ ] Add to lecturer navigation menu
- [ ] Style AI suggestions attractively (cards, icons)

**Success criteria:**
- Lecturer can request AI analysis for any team
- AI suggestions display within 5 seconds
- Evaluation form saves all criteria scores
- Grade summary calculates correctly

**UI Features:**
- [ ] AI suggestions shown as cards with icons
- [ ] Loading animation while AI processes
- [ ] Evaluation criteria as sliders (1-10 scale)
- [ ] Auto-save evaluation progress
- [ ] Export grades to CSV

---

### ğŸ”µ FE2 (Peer Reviews + Submissions UI)
**Má»¥c tiÃªu:** Build peer review and submission interfaces

**CÃ´ng viá»‡c:**
- [ ] Create `frontend/src/services/peerReviewService.js`
- [ ] Create `frontend/src/services/submissionService.js`
- [ ] Create components:
  - [ ] `PeerReviewForm.jsx` (submit review)
  - [ ] `PeerReviewResults.jsx` (view anonymized feedback)
  - [ ] `TeamMemberRatings.jsx` (aggregate scores)
  - [ ] `MilestoneTimeline.jsx` (visual timeline)
  - [ ] `SubmissionForm.jsx` (submit for checkpoint)
  - [ ] `SubmissionHistory.jsx` (past submissions)
  - [ ] `ResourceLibrary.jsx` (team resources)
- [ ] Create page: `frontend/src/pages/PeerReviewsPage.jsx`
- [ ] Create page: `frontend/src/pages/SubmissionsPage.jsx`
- [ ] Add countdown timer for submission deadlines
- [ ] Add file upload component (if needed)

**Success criteria:**
- Students can review all team members
- Anonymized results viewable after sprint ends
- Submissions work before deadline
- Visual countdown for deadlines
- Resources organized and searchable

**UI Features:**
- [ ] Star rating component for scores
- [ ] Anonymous feedback display (no names)
- [ ] Milestone timeline with checkpoints
- [ ] Deadline countdown widget
- [ ] File drag-and-drop upload
- [ ] Resource cards with type icons

---

## ğŸ§ª Testing Checklist Phase 4

### AI Mentoring Test
```
1. Lecturer navigates to Mentoring page
2. Selects team to analyze
3. Clicks "Get AI Suggestions"
4. Loading indicator appears
5. AI suggestions display within 5 seconds
6. Suggestions are relevant to team data
7. Log is saved for future reference
```

### Peer Review Test
```
1. Student opens Peer Review form
2. Sees all team members except self
3. Rates each member on 3 criteria
4. Submits review
5. Cannot submit another for same member/sprint
6. After sprint ends, sees anonymized results
7. Average scores calculated correctly
```

### Submission Test
```
1. Team views project milestones
2. Sees upcoming checkpoint deadline
3. Creates submission with content/file
4. Submits before deadline (success)
5. Tries to edit after deadline (blocked)
6. Lecturer grades submission
7. Team sees grade and feedback
```

---

## â° Timeline Phase 4

| NgÃ y | Milestone | Owner |
|-----|-----------|-------|
| Feb 15-16 | AI integration + Peer Reviews BE | BE1, BE2 |
| Feb 17-18 | Milestones/Submissions + Evaluation BE | BE3, BE4 |
| Feb 19-20 | FE Mentoring + Peer Reviews UI | FE1, FE2 |
| Feb 21 | Full integration test + bug fixes | All |

---

## ğŸš¨ Common Issues Phase 4

**Issue:** Gemini API rate limit exceeded  
â†’ Implement request queuing  
â†’ Add exponential backoff retry

**Issue:** AI suggestions not relevant  
â†’ Improve prompt with more context  
â†’ Add team history data to prompt

**Issue:** Peer review not anonymous  
â†’ Verify API response doesn't include reviewer_id  
â†’ Check frontend doesn't display reviewer info

**Issue:** Submission deadline check wrong  
â†’ Use UTC timezone for all datetime comparisons  
â†’ Add buffer time (5 min grace period)

**Issue:** File upload fails  
â†’ Check file size limits  
â†’ Verify storage service configured

---

## ğŸ“ Phase 4 Complete = MVP Ready!

Sau khi Phase 4 hoÃ n thÃ nh, há»‡ thá»‘ng cÃ³ Ä‘áº§y Ä‘á»§:
- âœ… User management + Auth
- âœ… Academic management (classes, subjects, semesters)
- âœ… Project formation (topics, teams, projects)
- âœ… Agile workflow (sprints, tasks)
- âœ… Real-time communication (chat, video)
- âœ… AI-powered mentoring
- âœ… Peer reviews + Evaluation
- âœ… Milestones + Submissions

**Tá»•ng: ~110 API endpoints + Full-featured UI**

---

## âœ… Khi xong Phase 4

1. Run full system test (all features)
2. Performance testing (load test)
3. Security audit (auth, CORS, SQL injection)
4. Documentation update (API docs, user manual)
5. Deploy to staging environment
6. User acceptance testing (UAT)

---

**ChÃºc báº¡n lÃ m viá»‡c vui váº»! ğŸš€**  
*Phase 4 hoÃ n thÃ nh = CollabSphere MVP ready for production! ğŸ‰*
